/*******************************************************************************
* Copyright 2014-2019 Intel Corporation.
*
* This software and the related documents are Intel copyrighted  materials,  and
* your use of  them is  governed by the  express license  under which  they were
* provided to you (License).  Unless the License provides otherwise, you may not
* use, modify, copy, publish, distribute,  disclose or transmit this software or
* the related documents without Intel's prior written permission.
*
* This software and the related documents  are provided as  is,  with no express
* or implied  warranties,  other  than those  that are  expressly stated  in the
* License.
*******************************************************************************/

/* Defines the classes/types/consts etc of the daal::algorithms::neural_networks::layers::loss::softmax_cross::backward namespace of DAAL */

{% from 'jinjadefs.tmpl' import declare_module, add_compute, add_compute2, in_namespace, add_includes,
                                add_getitem, add_aliases, add_ignores, handle_all_templates, cls_with_iface %}
{% set ns  = 'algorithms::neural_networks::layers::loss::softmax_cross::backward' %}
{% set module  = 'backward' %}
{% set package = 'algorithms.neural_networks.layers.loss.softmax_cross' %}

// see jinjadefs.tmpl for all configuration options evaluated by standard macros.
//   E.g. 'needpatch', 'ignore', 'steps', 'methods' and others
{% set cfg = {
    'includes': [
        'algorithms/neural_networks/layers/loss/softmax_cross_layer_backward_types.h',
        'algorithms/neural_networks/layers/loss/softmax_cross_layer_backward.h',
    ],
    'classes': [
        'Input',
        'Result',
    ],
    'methods': [
        'daal::algorithms::neural_networks::layers::loss::softmax_cross::defaultDense',
    ],
    'templates': {
        'Batch': [['fptype', fptypes, 'float'], ['method', 'methods', 'daal::algorithms::neural_networks::layers::loss::softmax_cross::defaultDense']],
        'Result::allocate': [['fptype', fptypes, '']],
    },
} %}

{{declare_module('daal.'+package, module)}}

// define the namespace needed as being used
// we only include those we need to save SWIG compile time
#define USE_algorithms
#define USE_algorithms__neural_networks
#define USE_algorithms__neural_networks__initializers
#define USE_algorithms__engines
#define USE_algorithms__engines__mt19937
#define USE_algorithms__neural_networks__initializers__uniform
#define USE_algorithms__neural_networks__layers
#define USE_algorithms__neural_networks__layers__backward
#define USE_algorithms__neural_networks__layers__loss
#define USE_algorithms__neural_networks__layers__loss__backward
#define USE_algorithms__neural_networks__layers__loss__softmax_cross
#define USE_algorithms__neural_networks__layers__loss__softmax_cross__backward
#define USE_algorithms__neural_networks__layers__softmax
#define USE_algorithms__neural_networks__layers__softmax__backward

%include "daal_common.i"

// renaming, typemaps need to go before declarations -> put them here
// E.g. if a list of get/set methods follows here
// Input: using loss::backward::Input::get;
// Input: using loss::backward::Input::set;
%rename(getLayerData) /*data_management::TensorPtr */ daal::{{ns}}::interface1::Input::get(LayerDataId id) const;
%rename(setLayerData) /*void */ daal::{{ns}}::interface1::Input::set(LayerDataId id, const data_management::TensorPtr &value);
// Result: using loss::backward::Result::get;
// Result: using loss::backward::Result::set;

{% call() in_namespace('daal::algorithms::neural_networks::layers::loss::softmax_cross') %}
class Parameter;
enum LayerDataId;
{% endcall %}
{% call() in_namespace('::'.join(['daal', ns])) %}
class {{cls_with_iface('Batch', cfg)}};
{% endcall %}

// only import the last module in package hierachy (omit importing its parents)
%import "algorithms__neural_networks__initializers__uniform.i"
%import "algorithms__neural_networks__layers__loss__backward.i"

// standard/basic type mappings
%import <std_string.i>

%{
#include <daal.h>
using namespace daal::algorithms::neural_networks::layers::loss::softmax_cross::backward;
%}

// declare to-be-ignored classes *before* scanning headers
{{add_ignores(cfg,ns)}}

// Let swig do the heavy-lifting: parse the headers and
//  extract the interfaces
{{add_includes(cfg)}}

{% call() in_namespace('::'.join(['daal', ns])) %}
    // Add our compute wrappers
    {{add_compute("Batch")}}
    // no Online
    // no Distributed

    // now all template instantiations
    {{handle_all_templates(ns, cfg)}}

{% endcall %}

{{add_aliases(cfg)}}
