/*******************************************************************************
* Copyright 2014-2019 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*******************************************************************************/

/* Defines the classes/types/consts etc of the daal::algorithms::neural_networks::layers::loss::logistic_cross::backward namespace of DAAL */

{% from 'jinjadefs.tmpl' import declare_module, add_compute, add_compute2, in_namespace, add_includes,
                                add_getitem, add_aliases, add_ignores, handle_all_templates, cls_with_iface %}
{% set ns  = 'algorithms::neural_networks::layers::loss::logistic_cross::backward' %}
{% set module  = 'backward' %}
{% set package = 'algorithms.neural_networks.layers.loss.logistic_cross' %}

// see jinjadefs.tmpl for all configuration options evaluated by standard macros.
//   E.g. 'needpatch', 'ignore', 'steps', 'methods' and others
{% set cfg = {
    'includes': [
        'algorithms/neural_networks/layers/loss/logistic_cross_layer_backward_types.h',
        'algorithms/neural_networks/layers/loss/logistic_cross_layer_backward.h',
    ],
    'classes': [
        'Input',
        'Result',
    ],
    'methods': [
        'daal::algorithms::neural_networks::layers::loss::logistic_cross::defaultDense',
    ],
    'templates': {
        'Batch': [['fptype', fptypes, 'float'], ['method', 'methods', 'daal::algorithms::neural_networks::layers::loss::logistic_cross::defaultDense']],
        'Result::allocate': [['fptype', fptypes, '']],
    },
} %}

{{declare_module('daal.'+package, module)}}

// define the namespace needed as being used
// we only include those we need to save SWIG compile time
#define USE_algorithms
#define USE_algorithms__neural_networks
#define USE_algorithms__neural_networks__initializers
#define USE_algorithms__engines
#define USE_algorithms__engines__mt19937
#define USE_algorithms__neural_networks__initializers__uniform
#define USE_algorithms__neural_networks__layers
#define USE_algorithms__neural_networks__layers__backward
#define USE_algorithms__neural_networks__layers__loss
#define USE_algorithms__neural_networks__layers__loss__backward
#define USE_algorithms__neural_networks__layers__loss__logistic_cross
#define USE_algorithms__neural_networks__layers__loss__logistic_cross__backward
#define USE_algorithms__neural_networks__layers__logistic
#define USE_algorithms__neural_networks__layers__logistic__backward

%include "daal_common.i"

// renaming, typemaps need to go before declarations -> put them here
// E.g. if a list of get/set methods follows here
// Input: using loss::backward::Input::get;
// Input: using loss::backward::Input::set;
%rename(getLayerData) /*data_management::TensorPtr */ daal::{{ns}}::interface1::Input::get(LayerDataId id) const;
%rename(setLayerData) /*void */ daal::{{ns}}::interface1::Input::set(LayerDataId id, const data_management::TensorPtr &value);
// Result: using loss::backward::Result::get;
// Result: using loss::backward::Result::set;

{% call() in_namespace('daal::algorithms::neural_networks::layers::loss::logistic_cross') %}
class Parameter;
enum LayerDataId;
{% endcall %}
{% call() in_namespace('::'.join(['daal', ns])) %}
class {{cls_with_iface('Batch', cfg)}};
{% endcall %}

// only import the last module in package hierachy (omit importing its parents)
%import "algorithms__neural_networks__initializers__uniform.i"
%import "algorithms__neural_networks__layers__loss__backward.i"

// standard/basic type mappings
%import <std_string.i>

%{
#include <daal.h>
using namespace daal::algorithms::neural_networks::layers::loss::logistic_cross::backward;
%}

// declare to-be-ignored classes *before* scanning headers
{{add_ignores(cfg,ns)}}

// Let swig do the heavy-lifting: parse the headers and
//  extract the interfaces
{{add_includes(cfg)}}

{% call() in_namespace('::'.join(['daal', ns])) %}
    // Add our compute wrappers
    {{add_compute("Batch")}}
    // no Online
    // no Distributed

    // now all template instantiations
    {{handle_all_templates(ns, cfg)}}

{% endcall %}

{{add_aliases(cfg)}}
